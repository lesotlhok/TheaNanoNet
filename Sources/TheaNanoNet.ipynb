{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NanoNet THEA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\"\n",
    "import numpy as np\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, CSVLogger, ReduceLROnPlateau, EarlyStopping, TensorBoard\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.metrics import Recall, Precision, MeanIoU\n",
    "from glob import glob\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "from tensorflow.keras.layers import Conv2D, MaxPool2D, Activation, BatchNormalization, LayerNormalization\n",
    "from tensorflow.keras.layers import UpSampling2D, SeparableConv2D, Input\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D, ZeroPadding2D, Cropping2D\n",
    "from tensorflow.keras.layers import Add, Concatenate, Lambda, Reshape\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from se import squeeze_excite_block\n",
    "import numpy as np\n",
    "import cv2\n",
    "from glob import glob\n",
    "from tensorflow.keras import backend as K\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.utils import CustomObjectScope\n",
    "\n",
    "\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, CSVLogger, ReduceLROnPlateau, EarlyStopping, TensorBoard\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.metrics import Recall, Precision, MeanIoU\n",
    "import json\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "H = 256\n",
    "W = 256\n",
    "\n",
    "def load_names(path, file_path):\n",
    "    f = open(file_path, \"r\")\n",
    "    data = f.read().split(\"\\n\")[:-1]\n",
    "    images = [os.path.join(path,\"images\", name) + \".jpg\" for name in data]\n",
    "    masks = [os.path.join(path,\"masks\", name) + \".jpg\" for name in data]\n",
    "    return images, masks\n",
    "\n",
    "def load_data(path):\n",
    "    train_names_path = f\"C:/thea/TheaNanoNet/DataSet/Kvasir-SEG/train.txt\"\n",
    "    valid_names_path = f\"C:/thea/TheaNanoNet/DataSet/Kvasir-SEG/val.txt\"\n",
    "\n",
    "    train_x, train_y = load_names(path, train_names_path)\n",
    "    valid_x, valid_y = load_names(path, valid_names_path)\n",
    "\n",
    "    return (train_x, train_y), (valid_x, valid_y)\n",
    "\n",
    "def read_image(path):\n",
    "    path = path.decode()\n",
    "    print(\"Reading image from path:\", path)\n",
    "    x = cv2.imread(path, cv2.IMREAD_COLOR)\n",
    "    x = cv2.resize(x, (W, H))\n",
    "    x = x/255.0\n",
    "    x = x.astype(np.float32)\n",
    "    return x\n",
    "\n",
    "def read_mask(path):\n",
    "    path = path.decode()\n",
    "    x = tf.io.read_file(path)\n",
    "    x = tf.image.decode_jpeg(x, channels=1)\n",
    "    x = tf.image.resize(x, [H, W])\n",
    "    x = tf.cast(x, tf.float32) / 255.0\n",
    "    return x\n",
    "\n",
    "def tf_parse(x, y):\n",
    "    def _parse(x, y):\n",
    "        x = read_image(x)\n",
    "        y = read_mask(y)\n",
    "        return x, y\n",
    "\n",
    "    x, y = tf.numpy_function(_parse, [x, y], [tf.float32, tf.float32])\n",
    "    x.set_shape([H, W, 3])\n",
    "    y.set_shape([H, W, 1])\n",
    "    return x, y\n",
    "\n",
    "\n",
    "def tf_dataset(x, y, batch=8):\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((x, y))\n",
    "    dataset = dataset.map(tf_parse)\n",
    "    dataset = dataset.batch(batch)\n",
    "    dataset = dataset.repeat()\n",
    "    dataset = dataset.prefetch(tf.data.experimental.AUTOTUNE)\n",
    "    return dataset"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Residual Block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def residual_block(x, num_filters):\n",
    "    x_init = x\n",
    "    x = Conv2D(num_filters//4, (1, 1), padding=\"same\")(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation(\"relu\")(x)\n",
    "\n",
    "    x = Conv2D(num_filters//4, (3, 3), padding=\"same\")(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation(\"relu\")(x)\n",
    "\n",
    "    x = Conv2D(num_filters, (3, 3), padding=\"same\")(x)\n",
    "    x = BatchNormalization()(x)\n",
    "\n",
    "    s = Conv2D(num_filters, (1, 1), padding=\"same\")(x_init)\n",
    "    s = BatchNormalization()(x)\n",
    "\n",
    "    x = Add()([x, s])\n",
    "    x = Activation(\"relu\")(x)\n",
    "    x = squeeze_excite_block(x)\n",
    "    return x"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NanoNet A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NanoNet_A(input_shape):\n",
    "\n",
    "    f = [32, 64, 128]\n",
    "    inputs = Input(shape=input_shape, name=\"input_image\")\n",
    "\n",
    "    ## Encoder\n",
    "    encoder = MobileNetV2(input_tensor=inputs, weights=\"imagenet\", include_top=False, alpha=0.50)\n",
    "    encoder_output = encoder.get_layer(name=\"block_6_expand_relu\").output\n",
    "    skip_connections_name = [\"input_image\", \"block_1_expand_relu\", \"block_3_expand_relu\"]\n",
    "\n",
    "    x = residual_block(encoder_output, 192)\n",
    "\n",
    "    ## Decoder\n",
    "    for i in range(1, len(skip_connections_name)+1, 1):\n",
    "        x_skip = encoder.get_layer(skip_connections_name[-i]).output\n",
    "        x_skip = Conv2D(f[-i], (1, 1), padding=\"same\")(x_skip)\n",
    "        x_skip = BatchNormalization()(x_skip)\n",
    "        x_skip = Activation(\"relu\")(x_skip)\n",
    "\n",
    "        x = UpSampling2D((2, 2), interpolation='bilinear')(x)\n",
    "\n",
    "        try:\n",
    "            x = Concatenate()([x, x_skip])\n",
    "        except Exception as e:\n",
    "            x = Cropping2D(cropping=((1, 0), (0, 0)))(x)\n",
    "            x = Concatenate()([x, x_skip])\n",
    "\n",
    "        x = residual_block(x, f[-i])\n",
    "\n",
    "    ## Output\n",
    "    x = Conv2D(1, (1, 1), padding=\"same\")(x)\n",
    "    x = Activation(\"sigmoid\")(x)\n",
    "\n",
    "    model = Model(inputs=inputs, outputs=x)\n",
    "    return model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NanoNet B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NanoNet_B(input_shape):\n",
    "    f = [32, 64, 96]\n",
    "    inputs = Input(shape=input_shape, name=\"input_image\")\n",
    "\n",
    "    ## Encoder\n",
    "    encoder = MobileNetV2(input_tensor=inputs, weights=\"imagenet\", include_top=False, alpha=0.35)\n",
    "    encoder_output = encoder.get_layer(name=\"block_6_expand_relu\").output\n",
    "    skip_connections_name = [\"input_image\", \"block_1_expand_relu\", \"block_3_expand_relu\"]\n",
    "\n",
    "    x = residual_block(encoder_output, 128)\n",
    "\n",
    "    ## Decoder\n",
    "    for i in range(1, len(skip_connections_name)+1, 1):\n",
    "        x_skip = encoder.get_layer(skip_connections_name[-i]).output\n",
    "        x_skip = Conv2D(f[-i], (1, 1), padding=\"same\")(x_skip)\n",
    "        x_skip = BatchNormalization()(x_skip)\n",
    "        x_skip = Activation(\"relu\")(x_skip)\n",
    "\n",
    "        x = UpSampling2D((2, 2), interpolation='bilinear')(x)\n",
    "\n",
    "        try:\n",
    "            x = Concatenate()([x, x_skip])\n",
    "        except Exception as e:\n",
    "            x = Cropping2D(cropping=((1, 0), (0, 0)))(x)\n",
    "            x = Concatenate()([x, x_skip])\n",
    "\n",
    "        x = residual_block(x, f[-i])\n",
    "\n",
    "    ## Output\n",
    "    x = Conv2D(1, (1, 1), padding=\"same\")(x)\n",
    "    x = Activation(\"sigmoid\")(x)\n",
    "\n",
    "    model = Model(inputs=inputs, outputs=x)\n",
    "    return model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NanoNet C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thea",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "efac005d3de3b7bc026c9cbf33f4b11fc7f97ffdcc82562409d2f04107140a76"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
